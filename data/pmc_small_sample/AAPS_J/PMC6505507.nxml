<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.0 20120330//EN" "JATS-archivearticle1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article"><?properties open_access?><front><journal-meta><journal-id journal-id-type="nlm-ta">AAPS J</journal-id><journal-id journal-id-type="iso-abbrev">AAPS J</journal-id><journal-title-group><journal-title>The AAPS Journal</journal-title></journal-title-group><issn pub-type="epub">1550-7416</issn><publisher><publisher-name>Springer International Publishing</publisher-name><publisher-loc>Cham</publisher-loc></publisher></journal-meta><article-meta><article-id pub-id-type="pmid">30850918</article-id><article-id pub-id-type="pmc">6505507</article-id><article-id pub-id-type="publisher-id">310</article-id><article-id pub-id-type="doi">10.1208/s12248-019-0310-5</article-id><article-categories><subj-group subj-group-type="heading"><subject>Research Article</subject></subj-group></article-categories><title-group><article-title>Variability Attribution for Automated Model Building</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Ibrahim</surname><given-names>Moustafa M. A.</given-names></name><xref ref-type="aff" rid="Aff1">1</xref><xref ref-type="aff" rid="Aff2">2</xref></contrib><contrib contrib-type="author"><name><surname>Nordgren</surname><given-names>Rikard</given-names></name><xref ref-type="aff" rid="Aff1">1</xref></contrib><contrib contrib-type="author"><name><surname>Kjellsson</surname><given-names>Maria C.</given-names></name><xref ref-type="aff" rid="Aff1">1</xref></contrib><contrib contrib-type="author" corresp="yes"><name><surname>Karlsson</surname><given-names>Mats O.</given-names></name><address><phone>+46184714105</phone><email>mats.karlsson@farmbio.uu.se</email></address><xref ref-type="aff" rid="Aff1">1</xref></contrib><aff id="Aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ISNI">0000 0004 1936 9457</institution-id><institution-id institution-id-type="GRID">grid.8993.b</institution-id><institution>Department of Pharmaceutical Biosciences, </institution><institution>Uppsala University, </institution></institution-wrap>Uppsala, Sweden </aff><aff id="Aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ISNI">0000 0000 9853 2750</institution-id><institution-id institution-id-type="GRID">grid.412093.d</institution-id><institution>Department of Pharmacy Practice, </institution><institution>Helwan University, </institution></institution-wrap>Cairo, Egypt </aff></contrib-group><pub-date pub-type="epub"><day>8</day><month>3</month><year>2019</year></pub-date><pub-date pub-type="pmc-release"><day>8</day><month>3</month><year>2019</year></pub-date><pub-date pub-type="collection"><month>5</month><year>2019</year></pub-date><volume>21</volume><issue>3</issue><elocation-id>37</elocation-id><history><date date-type="received"><day>10</day><month>12</month><year>2018</year></date><date date-type="accepted"><day>19</day><month>2</month><year>2019</year></date></history><permissions><copyright-statement>&#x000a9; The Author(s) 2019</copyright-statement><license license-type="OpenAccess"><license-p><bold>Open Access</bold> This article is distributed under the terms of the Creative Commons Attribution 4.0 International License (http://creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution, and reproduction in any medium, provided you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license, and indicate if changes were made.</license-p></license></permissions><abstract id="Abs1"><p id="Par1">We investigated the possible advantages of using linearization to evaluate models of residual unexplained variability (RUV) for automated model building in a similar fashion to the recently developed method &#x0201c;residual modeling.&#x0201d; Residual modeling, although fast and easy to automate, cannot identify the impact of implementing the needed RUV model on the imprecision of the rest of model parameters. We used six RUV models to be tested with 12 real data examples. Each example was first linearized; then, we assessed the agreement in improvement of fit between the base model and its extended models for linearization and conventional analysis, in comparison to residual modeling performance. Afterward, we compared the estimates of parameters&#x02019; variabilities and their uncertainties obtained by linearization to conventional analysis. Linearization accurately identified and quantified the nature and magnitude of RUV model misspecification similar to residual modeling. In addition, linearization identified the direction of change and quantified the magnitude of this change in variability parameters and their uncertainties. This method is implemented in the software package PsN for automated model building/evaluation with continuous data.</p><sec><title>Electronic supplementary material</title><p>The online version of this article (10.1208/s12248-019-0310-5) contains supplementary material, which is available to authorized users.</p></sec></abstract><kwd-group xml:lang="en"><title>KEY WORDS</title><kwd>automated model building</kwd><kwd>linearization</kwd><kwd>model evaluation</kwd><kwd>nonlinear mixed effects models</kwd><kwd>stochastic model</kwd></kwd-group><funding-group><award-group><funding-source><institution>Uppsala University</institution></funding-source></award-group></funding-group><custom-meta-group><custom-meta><meta-name>issue-copyright-statement</meta-name><meta-value>&#x000a9; American Association of Pharmaceutical Scientists 2019</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="Sec1"><title>INTRODUCTION</title><p id="Par2">Nonlinear mixed effect (NLME) modeling, commonly known as the population approach, is increasingly used to describe longitudinal data from preclinical/clinical experiments, either to improve the efficiency of the drug development process and subsequent dosing, or increase the understanding of the studied underlying pathophysiological system (<xref ref-type="bibr" rid="CR1">1</xref>). In contrast to naive pooling approach, which ignores individual differences, and two-stage approach, which does not distinguish between subject and observation variability, NLME models allow pooling of sparse data from different subjects while simultaneously quantifying multiple levels of variability, thanks to its mixed effects nature. In mixed-effects analysis, population parameters are included in a model as fixed effects, and the variability within this population as random effects. Random effects can incorporate variability on both the subject and observation levels, as inter-individual variability (IIV), between occasion variability, between study variability, and residual unexplained variability (RUV). This ability to identify different sources of variability is particularly critical to many clinical applications, e.g., therapeutic drug monitoring.</p><p id="Par3">For highly nonlinear models, extending the structural base model to include covariates or test different models for random effects can be tedious and interrupted by numerical difficulties. These problems increase exponentially with increasing the complexity of the structure, covariate, and variability models. To overcome such computational and time-intensive burden, linear approximation of first-order conditional estimation (FOCE) method was proposed and applied as a diagnostic tool for testing covariates and random effects (<xref ref-type="bibr" rid="CR2">2</xref>,<xref ref-type="bibr" rid="CR3">3</xref>). When successfully implemented, linearization substantially reduced runtimes compared to standard NLME models as the fixed effects are not estimated in the linearized models, but fixed to their estimates from the fit of the NLME model. Linearized models were shown to result in similar objective function values (OFVs) to the NLME models, and accurately identify significant covariate relations and stochastic components similar to conventional analysis. Hence, linearization output models in a standardized coding format, linearization was also recommended for automated model building by coupling to other covariate modeling algorithms as stepwise covariate method (SCM) or full random effects covariate modeling (FREM) (<xref ref-type="bibr" rid="CR4">4</xref>). However, linearized models still need to be estimated given the original observations similar to NLME models, so it might be sensitive to local minima or other estimation-related issues, especially in presence of interactions between empirical Bayes estimates and RUV models. Major deviations between the OFV of the linearized structure base model and its corresponding NLME model should be interpreted as a failure of implementation of linearization and must be solved prior to further investigations using the linearized model. It has not been shown previously that random effects estimated in linearized models or their uncertainties&#x02019; have similar values if estimated in the corresponding NLME models, which if true, will support the role of linearization in automated model building to predict changes in random variability assigned to model parameters upon the inclusion of a potential covariate or adoption of a new RUV model.</p><p id="Par4">Meanwhile, a new method &#x0201c;residual modeling&#x0201d; was proposed as a fast and robust diagnostic tool for assessing RUV models for NLME analysis with continuous outcomes (<xref ref-type="bibr" rid="CR5">5</xref>). Residual modeling treats the outputted residuals from a NLME model execution as a dependent variable to model its distribution&#x02019;s mean and variance by a linear base model, then this base model is extended to assess different RUV extensions. The improvement in the fit between the residuals base model and its extended versions can accurately identify the nature and magnitude of potential RUV model improvements/misspecifications, and hence, residual modeling has been already implemented for automated model building. Residual modeling uses a built-in library of six RUV extensions to model the variance of the residuals&#x02019; distribution from a NLME model execution. The built-in library includes autoregressive (AR1), dynamic transform both sides (dTBS), residuals&#x02019; IIV, power, t-distribution, and time-varying RUV models (<xref ref-type="bibr" rid="CR6">6</xref>&#x02013;<xref ref-type="bibr" rid="CR10">10</xref>). The investigated residuals were conditional weighted residuals (CWRES), conditional weighted residuals with interaction (CWRESI), individual weighted residuals (IWRES), and normalized prediction distribution errors (NPDE); CWRES outperformed the rest, as CWRES modeling correctly identified the type of the needed RUV model and accurately predicted both the estimates of parameters governing this RUV model and the magnitude of improvement of fit after implementing such RUV model. Residual modeling does not suffer from local minima problems or estimation related issues, as it is using residuals data, not the original observations. This is an advantage for its purpose in fast and robust selection of the best RUV model, but then by definition, it cannot predict the impact of implementing a new RUV model on random variability assigned to the rest of model parameters or their uncertainties.</p><p id="Par5">Here, we investigated if linearization can predict variability attribution for automated model building on the inclusion of a new RUV extension. We used the same six RUV models from our previous work for residual modeling. (<xref ref-type="bibr" rid="CR5">5</xref>) First, we compared the performance of linearization to residual modeling in selecting the best RUV extension; then, we compared random effects&#x02019; estimates and uncertainties on linearized models with the different RUV extensions to their corresponding NLME models.</p></sec><sec id="Sec2"><title>METHODS</title><sec id="Sec3"><title>Linearization</title><p id="Par6">For continuous outcome, let <italic>y</italic><sub><italic>ij</italic></sub> be the observation <italic>j</italic> for individual <italic>i</italic>,&#x000a0;<italic>&#x003b8;</italic> is the vector of population parameters,&#x000a0;<italic>&#x003b7;</italic><sub><italic>i</italic></sub> is the vector of unexplained deviation of individual parameters <italic>&#x003b8;</italic><sub><italic>i</italic></sub> from the population parameters&#x000a0;<italic>&#x003b8;</italic>, <italic>x</italic><sub><italic>ij</italic></sub> is the vector of individual <italic>i</italic> design components as dose and sampling times, and <italic>&#x003b5;</italic><sub><italic>ij</italic></sub> is the residual error of observation <italic>j</italic> for individual <italic>i</italic>, then the NLME model describing the observations:<disp-formula id="Equ1"><label>1</label><alternatives><tex-math id="M1">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ {y}_{ij}=f\left(\theta, {\eta}_i,{x}_{ij}\right)+h $$\end{document}</tex-math><mml:math id="M2" display="block"><mml:msub><mml:mi>y</mml:mi><mml:mi mathvariant="italic">ij</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>f</mml:mi><mml:mfenced close=")" open="(" separators=",,"><mml:mi>&#x003b8;</mml:mi><mml:msub><mml:mi>&#x003b7;</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:msub><mml:mi>x</mml:mi><mml:mi mathvariant="italic">ij</mml:mi></mml:msub></mml:mfenced><mml:mo>+</mml:mo><mml:mi>h</mml:mi></mml:math><graphic xlink:href="12248_2019_310_Article_Equ1.gif" position="anchor"/></alternatives></disp-formula>where <italic>f</italic>&#x000a0;is model prediction, and <italic>h</italic> is the RUV model to be function of <italic>&#x003b5;</italic><sub><italic>ij</italic></sub>. Such model can be extended further for multivariate outcome, baseline or time varying covariates. Both random effects <italic>&#x003b7;</italic><sub><italic>i</italic></sub>&#x000a0;and <italic>&#x003b5;</italic><sub><italic>ij</italic></sub> are assumed to follow normal distribution with mean 0 and covariance matrix &#x003a9; and &#x003a3;, respectively, and the unknown model parameters are estimated by maximum likelihood. According to the way of the dependence of <italic>h</italic> on <italic>f</italic>, this NLME model can be linearized based on first-order Taylor expansion around <italic>&#x003b5;</italic><sub><italic>ij</italic></sub>&#x02009;=&#x02009;0 and the empirical Bayes estimate <inline-formula id="IEq1"><alternatives><tex-math id="M3">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ {\widehat{\eta}}_i $$\end{document}</tex-math><mml:math id="M4" display="inline"><mml:msub><mml:mover accent="true"><mml:mi>&#x003b7;</mml:mi><mml:mo stretchy="true">^</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12248_2019_310_Article_IEq1.gif"/></alternatives></inline-formula>:<disp-formula id="Equ2"><label>2</label><alternatives><tex-math id="M5">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ {y}_{ij}\approx f\left(\theta, {\widehat{\eta}}_i,{x}_{ij}\right)+{f}^{\prime}\left(\theta, {\widehat{\eta}}_i,{x}_{ij}\right)\left({\eta}_i-{\widehat{\eta}}_i\right)+{h}^{\prime}\left({\varepsilon}_{ij}-0\right)+\frac{\partial {h}^{\prime }}{\partial {\eta}_i}\left({\varepsilon}_{ij}-0\right)\left({\eta}_i-{\widehat{\eta}}_i\right) $$\end{document}</tex-math><mml:math id="M6" display="block"><mml:msub><mml:mi>y</mml:mi><mml:mi mathvariant="italic">ij</mml:mi></mml:msub><mml:mo>&#x02248;</mml:mo><mml:mi>f</mml:mi><mml:mfenced close=")" open="(" separators=",,"><mml:mi>&#x003b8;</mml:mi><mml:msub><mml:mover accent="true"><mml:mi>&#x003b7;</mml:mi><mml:mo stretchy="true">^</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub><mml:msub><mml:mi>x</mml:mi><mml:mi mathvariant="italic">ij</mml:mi></mml:msub></mml:mfenced><mml:mo>+</mml:mo><mml:msup><mml:mi>f</mml:mi><mml:mo>&#x02032;</mml:mo></mml:msup><mml:mfenced close=")" open="(" separators=",,"><mml:mi>&#x003b8;</mml:mi><mml:msub><mml:mover accent="true"><mml:mi>&#x003b7;</mml:mi><mml:mo stretchy="true">^</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub><mml:msub><mml:mi>x</mml:mi><mml:mi mathvariant="italic">ij</mml:mi></mml:msub></mml:mfenced><mml:mfenced close=")" open="(" separators=",,"><mml:mrow><mml:msub><mml:mi>&#x003b7;</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>&#x003b7;</mml:mi><mml:mo stretchy="true">^</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mfenced><mml:mo>+</mml:mo><mml:msup><mml:mi>h</mml:mi><mml:mo>&#x02032;</mml:mo></mml:msup><mml:mfenced close=")" open="("><mml:mrow><mml:msub><mml:mi>&#x003b5;</mml:mi><mml:mi mathvariant="italic">ij</mml:mi></mml:msub><mml:mo>&#x02212;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mfenced><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:mi>&#x02202;</mml:mi><mml:msup><mml:mi>h</mml:mi><mml:mo>&#x02032;</mml:mo></mml:msup></mml:mrow><mml:mrow><mml:mi>&#x02202;</mml:mi><mml:msub><mml:mi>&#x003b7;</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mfenced close=")" open="("><mml:mrow><mml:msub><mml:mi>&#x003b5;</mml:mi><mml:mi mathvariant="italic">ij</mml:mi></mml:msub><mml:mo>&#x02212;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mfenced><mml:mfenced close=")" open="("><mml:mrow><mml:msub><mml:mi>&#x003b7;</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>&#x003b7;</mml:mi><mml:mo stretchy="true">^</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mfenced></mml:math><graphic xlink:href="12248_2019_310_Article_Equ2.gif" position="anchor"/></alternatives></disp-formula><disp-formula id="Equ3"><label>3</label><alternatives><tex-math id="M7">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ {f}_{ij}=f\left(\theta, {\widehat{\eta}}_i,{x}_{ij}\right)+{f}^{\prime}\left(\theta, {\widehat{\eta}}_i,{x}_{ij}\right)\left({\eta}_i-{\widehat{\eta}}_i\right) $$\end{document}</tex-math><mml:math id="M8" display="block"><mml:msub><mml:mi>f</mml:mi><mml:mi mathvariant="italic">ij</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>f</mml:mi><mml:mfenced close=")" open="(" separators=",,"><mml:mi>&#x003b8;</mml:mi><mml:msub><mml:mover accent="true"><mml:mi>&#x003b7;</mml:mi><mml:mo stretchy="true">^</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub><mml:msub><mml:mi>x</mml:mi><mml:mi mathvariant="italic">ij</mml:mi></mml:msub></mml:mfenced><mml:mo>+</mml:mo><mml:msup><mml:mi>f</mml:mi><mml:mo>&#x02032;</mml:mo></mml:msup><mml:mfenced close=")" open="(" separators=",,"><mml:mi>&#x003b8;</mml:mi><mml:msub><mml:mover accent="true"><mml:mi>&#x003b7;</mml:mi><mml:mo stretchy="true">^</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub><mml:msub><mml:mi>x</mml:mi><mml:mi mathvariant="italic">ij</mml:mi></mml:msub></mml:mfenced><mml:mfenced close=")" open="("><mml:mrow><mml:msub><mml:mi>&#x003b7;</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>&#x003b7;</mml:mi><mml:mo stretchy="true">^</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mfenced></mml:math><graphic xlink:href="12248_2019_310_Article_Equ3.gif" position="anchor"/></alternatives></disp-formula><disp-formula id="Equ4"><label>4</label><alternatives><tex-math id="M9">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ {h}_{ij}={\varepsilon}_{ij}\ \left({h}^{\prime }+\frac{\partial {h}^{\prime }}{\partial {\eta}_i}\left({\eta}_i-{\widehat{\eta}}_i\right)\right) $$\end{document}</tex-math><mml:math id="M10" display="block"><mml:msub><mml:mi>h</mml:mi><mml:mi mathvariant="italic">ij</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>&#x003b5;</mml:mi><mml:mi mathvariant="italic">ij</mml:mi></mml:msub><mml:mspace width="0.25em"/><mml:mfenced close=")" open="(" separators=",,"><mml:mrow><mml:msup><mml:mi>h</mml:mi><mml:mo>&#x02032;</mml:mo></mml:msup><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:mi>&#x02202;</mml:mi><mml:msup><mml:mi>h</mml:mi><mml:mo>&#x02032;</mml:mo></mml:msup></mml:mrow><mml:mrow><mml:mi>&#x02202;</mml:mi><mml:msub><mml:mi>&#x003b7;</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mfenced close=")" open="("><mml:mrow><mml:msub><mml:mi>&#x003b7;</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>&#x003b7;</mml:mi><mml:mo stretchy="true">^</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced></mml:math><graphic xlink:href="12248_2019_310_Article_Equ4.gif" position="anchor"/></alternatives></disp-formula><disp-formula id="Equ5"><label>5</label><alternatives><tex-math id="M11">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ {y_{ij}}^{\ast }={f}_{ij}+{h}_{ij} $$\end{document}</tex-math><mml:math id="M12" display="block"><mml:msup><mml:msub><mml:mi>y</mml:mi><mml:mi mathvariant="italic">ij</mml:mi></mml:msub><mml:mo>&#x02217;</mml:mo></mml:msup><mml:mo>=</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mi mathvariant="italic">ij</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>h</mml:mi><mml:mi mathvariant="italic">ij</mml:mi></mml:msub></mml:math><graphic xlink:href="12248_2019_310_Article_Equ5.gif" position="anchor"/></alternatives></disp-formula></p><p id="Par7">where <italic>y</italic><sub><italic>ij</italic></sub><sup>&#x02217;</sup> is the linearized model, <italic>f</italic><sub><italic>ij</italic></sub> is the approximated individual predictions, and <italic>h</italic><sub><italic>ij</italic></sub> is the approximated individual residual errors.</p><p id="Par8">The NLME model is first evaluated to calculate the different partial derivatives and <inline-formula id="IEq2"><alternatives><tex-math id="M13">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ {\widehat{\eta}}_i $$\end{document}</tex-math><mml:math id="M14" display="inline"><mml:msub><mml:mover accent="true"><mml:mi>&#x003b7;</mml:mi><mml:mo stretchy="true">^</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12248_2019_310_Article_IEq2.gif"/></alternatives></inline-formula> needed, then <italic>y</italic><sub><italic>ij</italic></sub><sup>&#x02217;</sup> is estimated on the same dataset of the NLME model to obtain <italic>&#x003b7;</italic><sub><italic>i</italic></sub> and <italic>&#x003b5;</italic><sub><italic>ij</italic></sub>, as these are the only unknown parameters in <italic>y</italic><sub><italic>ij</italic></sub><sup>&#x02217;</sup>. With estimating only random effects alongside its standard coding format, <italic>y</italic><sub><italic>ij</italic></sub><sup>&#x02217;</sup> can be easily and quickly used as a base model for further explaining <italic>&#x003b7;</italic><sub><italic>i</italic></sub> with covariates or using different <italic>&#x003b5;</italic><sub><italic>ij</italic></sub> models (<xref ref-type="bibr" rid="CR3">3</xref>). Here, we extended (Eq. <xref rid="Equ5" ref-type="">5</xref>) to test six RUV models, and compare their goodness of fit, parameters&#x02019; variability estimates, and uncertainties to conventional testing by NLME models as follow and shown in the <xref ref-type="sec" rid="Sec8">Supplementary material</xref>.</p></sec><sec id="Sec4"><title>RUV extensions</title><p id="Par9">To test the dependence of <italic>&#x003b5;</italic><sub><italic>ij</italic></sub> at time point <italic>j</italic> on <italic>&#x003b5;</italic><sub><italic>ik</italic></sub> at time point k, <italic>autoregression</italic> (AR1) <italic>error model</italic> with one extra parameter can be implemented:<disp-formula id="Equ7"><label>6</label><alternatives><tex-math id="M15">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ \rho \left({\varepsilon}_{ij},{\varepsilon}_{ik}\right)={\mathrm{e}}^{-\left(\ln (2)/{t}_{1/2}\right)\left({time}_j-{time}_k\right)} $$\end{document}</tex-math><mml:math id="M16" display="block"><mml:mi>&#x003c1;</mml:mi><mml:mfenced close=")" open="(" separators=","><mml:msub><mml:mi>&#x003b5;</mml:mi><mml:mi mathvariant="italic">ij</mml:mi></mml:msub><mml:msub><mml:mi>&#x003b5;</mml:mi><mml:mi mathvariant="italic">ik</mml:mi></mml:msub></mml:mfenced><mml:mo>=</mml:mo><mml:msup><mml:mi mathvariant="normal">e</mml:mi><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mfenced close=")" open="("><mml:mrow><mml:mo>ln</mml:mo><mml:mfenced close=")" open="("><mml:mn>2</mml:mn></mml:mfenced><mml:mo>/</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mfenced close=")" open="("><mml:mrow><mml:msub><mml:mtext mathvariant="italic">time</mml:mtext><mml:mi>j</mml:mi></mml:msub><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mtext mathvariant="italic">time</mml:mtext><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:mfenced></mml:mrow></mml:msup></mml:math><graphic xlink:href="12248_2019_310_Article_Equ7.gif" position="anchor"/></alternatives></disp-formula></p><p id="Par10">where <italic>&#x003c1;</italic> is the correlation between these errors and <italic>t</italic><sub>1/2</sub> is the half-life of <italic>&#x003c1;</italic>. The improvement of fit after implementing AR1 error model in the linearized model (&#x02206;OFV<sub><italic>lin</italic>, <italic>AR</italic>1</sub>) is calculated as the difference in OFV of the linearized base model (Eq. <xref rid="Equ5" ref-type="">5</xref>) and OFV of the linearized model with AR1 error model (Eqs. <xref rid="Equ5" ref-type="">5</xref> and <xref rid="Equ7" ref-type="">6</xref>). &#x02206;OFV<sub><italic>lin</italic>, <italic>AR</italic>1</sub> is comparable to the improvement of fit on implementing AR1 error model in the NLME model (&#x02206;OFV<sub><italic>NLME</italic>, <italic>AR</italic>1</sub>) between the base NLME model (Eq. <xref rid="Equ1" ref-type="">1</xref>) and its AR1 error model extension.</p><p id="Par11">In presence of skewness in residuals distribution, <italic>dynamic transform both sides</italic> (dTBS) approach is useful through the estimation of a Box&#x02013;Cox shape parameter <italic>&#x003bb;</italic> and a power term <italic>&#x003b6;</italic> that also address possible scedasticity in residual magnitudes (<xref ref-type="bibr" rid="CR8">8</xref>,<xref ref-type="bibr" rid="CR9">9</xref>). Linearized models with dTBS approach follows (Eq. <xref rid="Equ8" ref-type="">7</xref>) if <italic>&#x003bb;</italic> was estimated to 0, and (Eq. <xref rid="Equ9" ref-type="">8</xref>) otherwise. Improvement of fit on dTBS implementation (&#x02206;OFV<sub><italic>lin</italic>, <italic>dTBS</italic></sub>) is the difference in OFVs of the dTBS linearized model with <italic>&#x003bb;</italic> and <italic>&#x003b6;</italic> fixed to 1 and 0, respectively, and the dTBS linearized model with both <italic>&#x003bb;</italic> and <italic>&#x003b6;</italic> estimated.<disp-formula id="Equ8"><label>7</label><alternatives><tex-math id="M17">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ \ln \left({y_{ij}}^{\ast}\right)=\ln \left({f}_{ij}\right)+{h}_{ij}\bullet {f_{ij}}^{\zeta } $$\end{document}</tex-math><mml:math id="M18" display="block"><mml:mo>ln</mml:mo><mml:mfenced close=")" open="("><mml:msup><mml:msub><mml:mi>y</mml:mi><mml:mi mathvariant="italic">ij</mml:mi></mml:msub><mml:mo>&#x02217;</mml:mo></mml:msup></mml:mfenced><mml:mo>=</mml:mo><mml:mo>ln</mml:mo><mml:mfenced close=")" open="("><mml:msub><mml:mi>f</mml:mi><mml:mi mathvariant="italic">ij</mml:mi></mml:msub></mml:mfenced><mml:mo>+</mml:mo><mml:msub><mml:mi>h</mml:mi><mml:mi mathvariant="italic">ij</mml:mi></mml:msub><mml:mo>&#x02219;</mml:mo><mml:msup><mml:msub><mml:mi>f</mml:mi><mml:mi mathvariant="italic">ij</mml:mi></mml:msub><mml:mi>&#x003b6;</mml:mi></mml:msup></mml:math><graphic xlink:href="12248_2019_310_Article_Equ8.gif" position="anchor"/></alternatives></disp-formula><disp-formula id="Equ9"><label>8</label><alternatives><tex-math id="M19">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ \frac{{{y_{ij}}^{\ast}}^{\lambda }-1}{\lambda }=\frac{{f_{ij}}^{\lambda }-1}{\lambda }+{h}_{ij}\bullet {f_{ij}}^{\zeta } $$\end{document}</tex-math><mml:math id="M20" display="block"><mml:mfrac><mml:mrow><mml:msup><mml:msup><mml:msub><mml:mi>y</mml:mi><mml:mi mathvariant="italic">ij</mml:mi></mml:msub><mml:mo>&#x02217;</mml:mo></mml:msup><mml:mi>&#x003bb;</mml:mi></mml:msup><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>&#x003bb;</mml:mi></mml:mfrac><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msup><mml:msub><mml:mi>f</mml:mi><mml:mi mathvariant="italic">ij</mml:mi></mml:msub><mml:mi>&#x003bb;</mml:mi></mml:msup><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>&#x003bb;</mml:mi></mml:mfrac><mml:mo>+</mml:mo><mml:msub><mml:mi>h</mml:mi><mml:mi mathvariant="italic">ij</mml:mi></mml:msub><mml:mo>&#x02219;</mml:mo><mml:msup><mml:msub><mml:mi>f</mml:mi><mml:mi mathvariant="italic">ij</mml:mi></mml:msub><mml:mi>&#x003b6;</mml:mi></mml:msup></mml:math><graphic xlink:href="12248_2019_310_Article_Equ9.gif" position="anchor"/></alternatives></disp-formula></p><p id="Par12">One of maximum likelihood assumptions regarding the residual error <italic>&#x003b5;</italic><sub><italic>ij</italic></sub> is being identically distributed, this assumption can be relaxed by adding <italic>inter-individual variability &#x003b7;</italic><sub><italic>i</italic>, <italic>RUV</italic></sub>
<italic>on the residuals</italic> to allow different RUV magnitudes. Improvement of such extension in the fit of the linearized model (&#x02206;OFV<sub><italic>lin</italic>, <italic>IIV</italic></sub>) is the difference in OFVs of (Eq. <xref rid="Equ5" ref-type="">5</xref>) and (Eq. <xref rid="Equ10" ref-type="">9</xref>).<disp-formula id="Equ10"><label>9</label><alternatives><tex-math id="M21">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ {y_{ij}}^{\ast }={f}_{ij}+{h}_{ij}\bullet {e}^{\eta_{i, RUV}} $$\end{document}</tex-math><mml:math id="M22" display="block"><mml:msup><mml:msub><mml:mi>y</mml:mi><mml:mi mathvariant="italic">ij</mml:mi></mml:msub><mml:mo>&#x02217;</mml:mo></mml:msup><mml:mo>=</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mi mathvariant="italic">ij</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>h</mml:mi><mml:mi mathvariant="italic">ij</mml:mi></mml:msub><mml:mo>&#x02219;</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:msub><mml:mi>&#x003b7;</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="italic">RUV</mml:mi></mml:mrow></mml:msub></mml:msup></mml:math><graphic xlink:href="12248_2019_310_Article_Equ10.gif" position="anchor"/></alternatives></disp-formula></p><p id="Par13">In absence of skewness, the dependence of residuals magnitude on model predictions can be corrected with <italic>&#x003b6;</italic> alone in what is known as <italic>power RUV model</italic>. Improvement of fit on applying the power RUV model to the linearized models (&#x02206;OFV<sub><italic>lin</italic>, <italic>&#x003b6;</italic></sub>) is the difference in OFVs of (Eq. <xref rid="Equ5" ref-type="">5</xref>) and (Eq. <xref rid="Equ11" ref-type="">10</xref>).<disp-formula id="Equ11"><label>10</label><alternatives><tex-math id="M23">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ {y_{ij}}^{\ast }={f}_{ij}+{h}_{ij}\bullet {f_{ij}}^{\zeta } $$\end{document}</tex-math><mml:math id="M24" display="block"><mml:msup><mml:msub><mml:mi>y</mml:mi><mml:mi mathvariant="italic">ij</mml:mi></mml:msub><mml:mo>&#x02217;</mml:mo></mml:msup><mml:mo>=</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mi mathvariant="italic">ij</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>h</mml:mi><mml:mi mathvariant="italic">ij</mml:mi></mml:msub><mml:mo>&#x02219;</mml:mo><mml:msup><mml:msub><mml:mi>f</mml:mi><mml:mi mathvariant="italic">ij</mml:mi></mml:msub><mml:mi>&#x003b6;</mml:mi></mml:msup></mml:math><graphic xlink:href="12248_2019_310_Article_Equ11.gif" position="anchor"/></alternatives></disp-formula></p><p id="Par14">Assuming normal distribution of residuals means that large errors do not exist, which if not true will force maximum likelihood estimation to shift model parameters&#x02019; estimates to fulfill small errors assumption. This bias can be avoided by introducing <italic>t-distributed residuals</italic>. The Laplacian method with user-defined conditional likelihood (<italic>L</italic>) had to be used for a Laplace linearized base model (Eq. <xref rid="Equ12" ref-type="">11</xref>) and linearized model with t-distributed residuals (Eq. <xref rid="Equ13" ref-type="">12</xref>), where <italic>&#x003c3;</italic> is the square root of <italic>h</italic><sub><italic>ij</italic></sub>, and <italic>&#x003c5;</italic> is the degrees of freedom; the difference of these models&#x02019; OFVs is &#x02206;OFV<sub><italic>lin</italic>, <italic>&#x003c5;</italic></sub>.<disp-formula id="Equ12"><label>11</label><alternatives><tex-math id="M25">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ L=\left(1/\sqrt{2\pi {\sigma}^2}\right)\exp \left(-\frac{1}{2}{\left(\frac{{y_{ij}}^{\ast }-{f}_{ij}}{\sigma}\right)}^2\right) $$\end{document}</tex-math><mml:math id="M26" display="block"><mml:mi>L</mml:mi><mml:mo>=</mml:mo><mml:mfenced close=")" open="("><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:msqrt><mml:mrow><mml:mn>2</mml:mn><mml:mi>&#x003c0;</mml:mi><mml:msup><mml:mi>&#x003c3;</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:msqrt></mml:mrow></mml:mfenced><mml:mo>exp</mml:mo><mml:mfenced close=")" open="("><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:msup><mml:mfenced close=")" open="("><mml:mfrac><mml:mrow><mml:msup><mml:msub><mml:mi>y</mml:mi><mml:mi mathvariant="italic">ij</mml:mi></mml:msub><mml:mo>&#x02217;</mml:mo></mml:msup><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mi mathvariant="italic">ij</mml:mi></mml:msub></mml:mrow><mml:mi>&#x003c3;</mml:mi></mml:mfrac></mml:mfenced><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mfenced></mml:math><graphic xlink:href="12248_2019_310_Article_Equ12.gif" position="anchor"/></alternatives></disp-formula><disp-formula id="Equ13"><label>12</label><alternatives><tex-math id="M27">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ L=\frac{\varGamma \left(\frac{\upsilon +1}{2}\right)}{\ \varGamma \left(\frac{\upsilon }{2}\sqrt{\upsilon \pi {\sigma}^2}\right)}{\left(1+\frac{1}{\upsilon }{\left(\frac{{y_{ij}}^{\ast }-{f}_{ij}}{\sigma}\right)}^2\right)}^{-\left(\frac{\upsilon +1}{2}\right)} $$\end{document}</tex-math><mml:math id="M28" display="block"><mml:mi>L</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>&#x00393;</mml:mi><mml:mfenced close=")" open="("><mml:mfrac><mml:mrow><mml:mi>&#x003c5;</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mn>2</mml:mn></mml:mfrac></mml:mfenced></mml:mrow><mml:mrow><mml:mspace width="0.25em"/><mml:mi>&#x00393;</mml:mi><mml:mfenced close=")" open="("><mml:mrow><mml:mfrac><mml:mi>&#x003c5;</mml:mi><mml:mn>2</mml:mn></mml:mfrac><mml:msqrt><mml:mrow><mml:mi mathvariant="italic">&#x003c5;&#x003c0;</mml:mi><mml:msup><mml:mi>&#x003c3;</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:msqrt></mml:mrow></mml:mfenced></mml:mrow></mml:mfrac><mml:msup><mml:mfenced close=")" open="("><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>&#x003c5;</mml:mi></mml:mfrac><mml:msup><mml:mfenced close=")" open="("><mml:mfrac><mml:mrow><mml:msup><mml:msub><mml:mi>y</mml:mi><mml:mi mathvariant="italic">ij</mml:mi></mml:msub><mml:mo>&#x02217;</mml:mo></mml:msup><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mi mathvariant="italic">ij</mml:mi></mml:msub></mml:mrow><mml:mi>&#x003c3;</mml:mi></mml:mfrac></mml:mfenced><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mfenced><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mfenced close=")" open="("><mml:mfrac><mml:mrow><mml:mi>&#x003c5;</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mn>2</mml:mn></mml:mfrac></mml:mfenced></mml:mrow></mml:msup></mml:math><graphic xlink:href="12248_2019_310_Article_Equ13.gif" position="anchor"/></alternatives></disp-formula></p><p id="Par15">Lastly, <italic>time-varying errors</italic> allow different error magnitudes for different time points. A typical example is that the absorption phase in a pharmacokinetic model can have larger errors than the elimination phase. This is implemented by allowing the change of the standard deviation of residuals to be a step function of the time or time after dose, at selected cutoff time point <italic>X</italic>.<disp-formula id="Equ14"><label>13</label><alternatives><tex-math id="M29">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ {\displaystyle \begin{array}{c}\omega ={\uptheta}_1\\ {} if\ \left( time&#x0003e;X\right)\kern0.75em \omega ={\uptheta}_2\\ {}{h}_{ij}=\upomega \bullet {\varepsilon}_{ij}\ \left({h}^{\prime }+\frac{\partial {h}^{\prime }}{\partial {\eta}_i}\left({\eta}_i-{\widehat{\eta}}_i\right)\right)\ \end{array}} $$\end{document}</tex-math><mml:math id="M30" display="block"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd><mml:maligngroup/><mml:mi>&#x003c9;</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mi mathvariant="normal">&#x003b8;</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:maligngroup/><mml:mtext mathvariant="italic">if</mml:mtext><mml:mspace width="0.25em"/><mml:mfenced close=")" open="("><mml:mrow><mml:mtext mathvariant="italic">time</mml:mtext><mml:mo>&#x0003e;</mml:mo><mml:mi>X</mml:mi></mml:mrow></mml:mfenced><mml:mspace width="0.75em"/><mml:mi>&#x003c9;</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mi mathvariant="normal">&#x003b8;</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:maligngroup/><mml:msub><mml:mi>h</mml:mi><mml:mi mathvariant="italic">ij</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi mathvariant="normal">&#x003c9;</mml:mi><mml:mo>&#x02219;</mml:mo><mml:msub><mml:mi>&#x003b5;</mml:mi><mml:mi mathvariant="italic">ij</mml:mi></mml:msub><mml:mspace width="0.25em"/><mml:mfenced close=")" open="("><mml:mrow><mml:msup><mml:mi>h</mml:mi><mml:mo>&#x02032;</mml:mo></mml:msup><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:mi>&#x02202;</mml:mi><mml:msup><mml:mi>h</mml:mi><mml:mo>&#x02032;</mml:mo></mml:msup></mml:mrow><mml:mrow><mml:mi>&#x02202;</mml:mi><mml:msub><mml:mi>&#x003b7;</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mfenced close=")" open="("><mml:mrow><mml:msub><mml:mi>&#x003b7;</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>&#x003b7;</mml:mi><mml:mo stretchy="true">^</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced><mml:mspace width="0.25em"/></mml:mtd></mml:mtr></mml:mtable></mml:math><graphic xlink:href="12248_2019_310_Article_Equ14.gif" position="anchor"/></alternatives></disp-formula></p><p id="Par16">where &#x003b8;<sub>1</sub> is the standard deviation of residuals before the cutoff time point <italic>X</italic>, &#x003b8;<sub>2</sub> is the standard deviation of residuals after this cutoff time point, and &#x003a3; is fixed to 1, as multiplying a random variable by constant (&#x003c9;&#x02009;&#x02219;&#x02009;<italic>&#x003b5;</italic><sub><italic>ij</italic></sub>) increase the variance by the square of this constant (&#x003c9;<sup>2</sup>). We used three cutoff points to divide the data into four equal sized groups, and the improvement of fit (&#x02206;OFV<sub><italic>lin</italic>, <italic>time</italic></sub>) after extending the linearized base model (Eqs. <xref rid="Equ4" ref-type="">4</xref> and <xref rid="Equ5" ref-type="">5</xref>) to the linearized model with time varying residuals (Eqs. <xref rid="Equ5" ref-type="">5</xref> and <xref rid="Equ14" ref-type="">13</xref>) is the difference between their respective OFVs.</p></sec><sec id="Sec5"><title>Evaluations</title><p id="Par17">These extended linearized models (example code in <xref ref-type="sec" rid="Sec8">Supplementary material</xref>) were estimated to obtain their respective improvement of fit &#x02206;OFV<sub><italic>lin</italic></sub>, as well as &#x003a9;s&#x02019; estimates and uncertainties. We compared the performance of &#x02206;OFV<sub><italic>lin</italic></sub> in predicting &#x02206;OFV<sub><italic>NLME</italic></sub> to that of &#x02206;OFV<sub><italic>Diagnostic</italic></sub> obtained by residual modeling, where <italic>diagnostic</italic> refers to the used residual. Afterwards, we compared &#x003a9;s&#x02019; estimates and uncertainties of linearized models to their respective NLME models as shown in Fig.&#x000a0;<xref rid="Fig1" ref-type="fig">1</xref>. We used 12 real data examples for our evaluation (Table <xref rid="Tab1" ref-type="table">I</xref>). Only when the linearized base model and the NLME base model had similar OFV were RUV extensions added and further estimated. All real data examples were treated as continuous. Asenapine effects were assessed using PANSS, which is a composite score, where items of positive, negative, and general nature are scored and combined into one assessment. Despite this, the asenapine data was treated as continuous data in the model. Also, the asenapine model was implemented with residuals&#x02019; IIV model from the start. Models varied in structure components from simple pharmacokinetic one compartment model as moxonodine, to complex description of nonlinear system of interacting multi-dependent variables as the integrated glucose-insulin (IGI) model. Seven models used log-transformed data. Two models used a combined error model, two models used a proportional error model and the remaining models used additive error models. NONMEM version 7.4.3 (ICON Development Solutions, Hanover, MD, USA) was used for the analysis (<xref ref-type="bibr" rid="CR22">22</xref>), with the aid of the <italic>linearize</italic> tool in PsN (<xref ref-type="bibr" rid="CR3">3</xref>,<xref ref-type="bibr" rid="CR23">23</xref>), and graphs were generated in R (<xref ref-type="bibr" rid="CR24">24</xref>). To obtain the improvement of fit by residual modeling (&#x02206;OFV<sub><italic>Diagnostic</italic></sub>) when testing the different RUV extensions on the real data examples, we used the <italic>resmod</italic> tool in PsN (<xref ref-type="bibr" rid="CR5">5</xref>).<fig id="Fig1"><label>Fig. 1</label><caption><p>Schematic presentation of the method used to evaluate linearization ability in predicting variability attributions</p></caption><graphic xlink:href="12248_2019_310_Fig1_HTML" id="MO1"/></fig><table-wrap id="Tab1"><label>Table I</label><caption><p>Summary of real data examples used for investigation</p></caption><table frame="hsides" rules="groups"><thead><tr><th>Model</th><th>Data type</th><th>RUV model</th><th>Transformation</th><th>No. of observations</th><th>No. of subjects</th><th>No. of THETAs</th><th>No. of OMEGAs including covariances</th><th>No. of SIGMAs</th></tr></thead><tbody><tr><td>Asenapine<sup>a</sup> (<xref ref-type="bibr" rid="CR11">11</xref>)</td><td>PD</td><td>Additive with IIV</td><td>&#x02013;</td><td>7728</td><td>1328</td><td>16</td><td>5</td><td>1</td></tr><tr><td>Clomethiazole (<xref ref-type="bibr" rid="CR12">12</xref>)</td><td>PK</td><td>Additive</td><td>Log</td><td>2177</td><td>772</td><td>10</td><td>5</td><td>1</td></tr><tr><td>Daunorubicin<sup>a</sup> (<xref ref-type="bibr" rid="CR13">13</xref>)</td><td>PD</td><td>Additive</td><td>Log</td><td>112</td><td>41</td><td>7</td><td>3</td><td>1</td></tr><tr><td>Digoxin<sup>a,b</sup> (<xref ref-type="bibr" rid="CR14">14</xref>)</td><td>PK/PD</td><td><p>PD: proportional</p><p>PK: additive</p></td><td>&#x02013;</td><td>941</td><td>225</td><td>6</td><td>3</td><td>1</td></tr><tr><td>Disufenton sodium<sup>a</sup> (<xref ref-type="bibr" rid="CR15">15</xref>)</td><td>PK</td><td>Additive</td><td>Log</td><td>1196</td><td>175</td><td>7</td><td>3</td><td>1</td></tr><tr><td>Ethambutol<sup>a</sup> (<xref ref-type="bibr" rid="CR16">16</xref>)</td><td>PK</td><td>Combined</td><td>Log</td><td>1869</td><td>189</td><td>8</td><td>3</td><td>1</td></tr><tr><td>IGI<sup>ab</sup> (<xref ref-type="bibr" rid="CR17">17</xref>)</td><td>PD</td><td>Additive</td><td>Log</td><td>6382</td><td>72</td><td>26</td><td>15</td><td>1</td></tr><tr><td>Miltefosine<sup>a</sup> (<xref ref-type="bibr" rid="CR18">18</xref>)</td><td>PK</td><td>Proportional</td><td>&#x02013;</td><td>350</td><td>31</td><td>7</td><td>4</td><td>1</td></tr><tr><td>Moxonodine<sup>a</sup> (<xref ref-type="bibr" rid="CR10">10</xref>)</td><td>PK</td><td>Additive</td><td>Log</td><td>1021</td><td>74</td><td>5</td><td>6</td><td>1</td></tr><tr><td>Paclitaxel<sup>a,c</sup> (<xref ref-type="bibr" rid="CR19">19</xref>)</td><td>PD</td><td>Combined</td><td>&#x02013;</td><td>530</td><td>46</td><td>6</td><td>3</td><td>1</td></tr><tr><td>Pefloxacin<sup>a</sup> (<xref ref-type="bibr" rid="CR20">20</xref>)</td><td>PK</td><td>Additive</td><td>Log</td><td>337</td><td>74</td><td>4</td><td>6</td><td>1</td></tr><tr><td>r-Hfsh (<xref ref-type="bibr" rid="CR21">21</xref>)</td><td>PK</td><td>Additive</td><td>&#x02013;</td><td>314</td><td>60</td><td>7</td><td>2</td><td>1</td></tr></tbody></table><table-wrap-foot><p><sup>a</sup>SIGMAs were fixed to 1 and modeled as THETAs (standard deviation)</p><p><sup>b</sup>More than one dependent variable</p><p><sup>c</sup>Additive component of RUV model was fixed</p></table-wrap-foot></table-wrap></p></sec></sec><sec id="Sec6"><title>RESULTS</title><p id="Par18">Linearization was successfully applied to all examples, justified by the similarities in the OFVs of the linearized base models and the NLME base models. All examples were extended successfully to the different RUV models, except for AR1 and t-distribution error models with Clomethiazole and the IGI models. All examples benefitted significantly with one or more of the RUV extensions, except for Daunorubicin model. Across all examples, the agreement between &#x02206;OFV<sub><italic>lin</italic></sub> and &#x02206;OFV<sub><italic>NLME</italic></sub> was good as shown in Fig.&#x000a0;<xref rid="Fig2" ref-type="fig">2</xref>. Comparing to the performance of residual modeling in predicting &#x02206;OFV<sub><italic>NLME</italic></sub>, linearization surpassed CWRESI, IWRES, and NPDE over all different ranges of &#x02206;OFV<sub><italic>NLME</italic></sub>, and performed better than CWRES at most ranges of &#x02206;OFV<sub><italic>NLME</italic></sub> except at low ranges of &#x02206;OFV<sub><italic>NLME</italic></sub>(~&#x02009;10) where CWRES was slightly better. Linearization identified accurately the most important RUV extension to all examples similar to conventional analysis, surpassing CWRES modeling that reversed the order of 1st and 2nd most important extensions with two examples, Ethambutol and Disufenton sodium models. Also, linearization identified the RUV extensions resulting in significant improvement of fit in all examples similar to conventional analysis, while CWRES modeling missed only t-distribution error model with Asenapine model, shown in Fig. <xref rid="Fig2" ref-type="fig">2</xref>. Asenapine model is the only model with residuals&#x02019; IIV model as the base model, which may be sufficient in explaining outliers and would turn the t-distributed error model rather less important. The median ratio of &#x00394;OFV<sub><italic>lin</italic></sub>/&#x00394;OFV<sub><italic>NLME</italic></sub> was 0.95 among models with significant improvement, compared to 0.8 for the median ratio of &#x00394;OFV<sub><italic>CWRES</italic></sub>/&#x00394;OFV<sub><italic>NLME</italic></sub>.<fig id="Fig2"><label>Fig. 2</label><caption><p>Plot of absolute &#x00394;OFV<sub><italic>NLME</italic></sub>versus absolute &#x00394;OFV for CWRES, CWRESI, IWRES, linearization, and NPDE among the real data examples for the six extended RUV models</p></caption><graphic xlink:href="12248_2019_310_Fig2_HTML" id="MO2"/></fig></p><p id="Par19">Regarding the estimates of &#x003a9;s on linearized models (&#x003a9;<sub><italic>lin</italic></sub>) and their respective estimates on NLME models (&#x003a9;<sub><italic>NLME</italic></sub>), they showed good agreement with only one outlier: AUC50&#x02019;s variability in asenapine model. A plot of log (&#x003a9;<sub><italic>NLME</italic></sub>) versus log (&#x003a9;<sub><italic>lin</italic></sub>) across all examples with base models and their RUV extensions is shown in Fig.&#x000a0;<xref rid="Fig3" ref-type="fig">3</xref>, with estimates less than &#x02212;&#x02009;4 on log scale excluded from the graph, given that these estimates are low and would not be considered in further model development. In total, nine estimates were excluded based on this, e.g., the variability assigned to the intercompartmental clearance in Clomethiazole model under IIV on RUV and dTBS extensions. Standard errors (SEs) of each &#x003a9;<sub><italic>lin</italic></sub> and its respective &#x003a9;<sub><italic>NLME</italic></sub> showed a good agreement in the commonly expected range of SEs for a well identifiable continuous data variability parameter (0&#x02013;1), and bad agreement at the extreme estimates of SE(&#x003a9;<sub><italic>NLME</italic></sub>), for instance, the SE of PAN0&#x02019;s variability in asenapine model was &#x0003e;&#x02009;1000 with both dTBS and power RUV extensions, which is unacceptable. This may be related to the scores used to measure asenapine effect, i.e., PANSS. A plot of the log-transformed estimates of SE(&#x003a9;<sub><italic>NLME</italic></sub>) and SE(&#x003a9;<sub><italic>lin</italic></sub>) is presented in Fig.&#x000a0;<xref rid="Fig4" ref-type="fig">4</xref>, with estimates less than &#x02212;&#x02009;4 on log scale excluded from the graph. Lastly, relative standard errors (RSEs) for each &#x003a9;<sub><italic>lin</italic></sub> and its corresponding &#x003a9;<sub><italic>NLME</italic></sub> were calculated on the standard deviation scale as (Eq. <xref rid="Equ15" ref-type="">14</xref>), and their log-transformed estimates are presented in Fig.&#x000a0;<xref rid="Fig5" ref-type="fig">5</xref>, that in addition to showing the same trends as Fig. <xref rid="Fig4" ref-type="fig">4</xref>, showed that standard errors after implementing t-distribution extensions are less predictable by linearization than the other RUV extensions.<disp-formula id="Equ15"><label>14</label><alternatives><tex-math id="M31">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ \mathrm{RSE}\left(\Omega \right)=\frac{\mathrm{SE}\left(\Omega \right)}{\Omega}/2 $$\end{document}</tex-math><mml:math id="M32" display="block"><mml:mi>RSE</mml:mi><mml:mfenced close=")" open="("><mml:mi mathvariant="normal">&#x003a9;</mml:mi></mml:mfenced><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>SE</mml:mi><mml:mfenced close=")" open="("><mml:mi mathvariant="normal">&#x003a9;</mml:mi></mml:mfenced></mml:mrow><mml:mi mathvariant="normal">&#x003a9;</mml:mi></mml:mfrac><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:math><graphic xlink:href="12248_2019_310_Article_Equ15.gif" position="anchor"/></alternatives></disp-formula><fig id="Fig3"><label>Fig. 3</label><caption><p>Plot of log (&#x003a9;<sub>NLME</sub>) versus log (&#x003a9;<sub>lin</sub>) across the real data examples for the six extended RUV models, with only one outlier: the variability assigned to AUC50 parameter in Asenapine model with all RUV extensions except t-distributed error model</p></caption><graphic xlink:href="12248_2019_310_Fig3_HTML" id="MO3"/></fig><fig id="Fig4"><label>Fig. 4</label><caption><p>Plot of log SE (&#x003a9;<sub>NLME</sub>) versus log SE (&#x003a9;<sub>lin</sub>) across the real data examples for the six extended RUV models. Departures (&#x000b1;&#x02009;2&#x000a0;units from identity line) are the log standard error estimates of the variabilities assigned to PAN0, AUC50 and RES parameters in Asenapine model, and BASE parameter in Paclitaxel model</p></caption><graphic xlink:href="12248_2019_310_Fig4_HTML" id="MO4"/></fig><fig id="Fig5"><label>Fig. 5</label><caption><p>Plot of log RSE (&#x003a9;<sub>NLME</sub>) versus log RSE (&#x003a9;<sub>lin</sub>) across the real data examples for the six extended RUV models. Departures (&#x000b1;&#x02009;2&#x000a0;units from identity line) are the log relative standard error estimates of the variabilities assigned to PAN0, AUC50, and RES parameters in Asenapine model, BASE parameter in Paclitaxel model, and V2 parameter in Clomethiazole model</p></caption><graphic xlink:href="12248_2019_310_Fig5_HTML" id="MO5"/></fig></p></sec><sec id="Sec7"><title>DISCUSSION</title><p id="Par20">In this paper, we explored if the use of linearization to identify and quantify RUV model misspecifications, similar to residual modeling (<xref ref-type="bibr" rid="CR5">5</xref>), can provide additional advantages. Residual modeling assesses whether RUV extensions are required to address an RUV misspecification. It is done in an extremely fast and robust way, thanks to the simple nature of models for residuals data. In case of multiple dependent variables, residual modeling evaluates the RUV extensions separately for each dependent variable, identifying which variable need which extension, and so reducing the risk of ending up with an over-parameterized NLME model. However, being estimated on residual data has shortcomings, as residual modeling cannot inform on the rest of the NLME model parameters. Implementation of a needed RUV extension in a NLME model would be expected to improve the uncertainties of &#x003a9; and &#x003b8; subsequently, as the latter is a function of the former. Linearization, in contrast to residual modeling, uses the calculated parameters&#x02019; partial derivatives with respect to <inline-formula id="IEq3"><alternatives><tex-math id="M33">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ {\widehat{\eta}}_i $$\end{document}</tex-math><mml:math id="M34" display="inline"><mml:msub><mml:mover accent="true"><mml:mi>&#x003b7;</mml:mi><mml:mo stretchy="true">^</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12248_2019_310_Article_IEq3.gif"/></alternatives></inline-formula> from the fit of the NLME model. It estimates the RUV model incorporating any extension and the random effects components given the same data as the NLME model. Thus, linearization can estimate explicitly the random effects and their uncertainties in the base and the extended model, and implicitly the magnitude and the direction of change in the random effects and their uncertainties, and that is what we had shown here.</p><p id="Par21">We successfully implemented six RUV extensions to the standardized linearization framework and linearized all real data examples. However, estimation difficulties were present when applying AR1 and t-distribution RUV extensions to the NLME/linearized models of Clomethiazole and the IGI, but not in their respective residual modeling. The agreement between &#x00394;OFV<sub><italic>lin</italic></sub> and &#x00394;OFV<sub><italic>NLME</italic></sub> when improvement of fit is &#x0003e;&#x02009;10 was nearly perfect, indicating that only the estimates of random effects were changing on implementing the different RUV extensions in the NLME models. Deviations would be expected if estimates of fixed effects were also changing. The overall prediction performance of &#x00394;OFV<sub><italic>NLME</italic></sub> by &#x00394;OFV<sub><italic>lin</italic></sub> was better than &#x00394;OFV<sub><italic>CWRES</italic></sub>, however not by much.</p><p id="Par22">Linearization identified and quantified the nature and the magnitude of RUV model misspecifications in these real data examples more accurately than CWRES modeling, the latter reversed the order of the most two important extensions in Ethambutol and Disufenton sodium models and could not identify t-distribution as a significant extension in Asenapine model. Even though it is a minor difference, it illustrated the high sensitivity of linearization to detect differences between the RUV extensions that introduce similar flexibility in the model, e.g., IIV and t-distribution RUV models both offer outlier robustness in the NLME model. This showed that conclusions drawn from the results of automated testing of RUV extensions will remain the same on replacement of residual modeling with linearization, and the only expected difference would be an increased run time for linearization of structure models with large random effects models.</p><p id="Par23">Regarding the prediction of the impact of RUV extensions on &#x003a9;<sub><italic>NLME</italic></sub>, linearization showed a good ability with only one outlier (the &#x003a9; assigned to AUC50 in Asenapine model). Interestingly, linearization underestimated this &#x003a9; with all RUV extensions except t-distribution. This underestimation issue will escalate when it comes to predicting SE(&#x003a9;<sub><italic>NLME</italic></sub>). Linearization did well in assessing the expected ranges of uncertainties of variability assigned to model parameters describing continuous data; more deviations occurred as uncertainties&#x02019; estimates moved away from that range, with the main problem being Asenapine model. This might point out that violation of assumptions regarding the nature of data will be a problematic in this automated testing procedure as Asenapine effects are measured using PANSS, which is a composite score, but treated as continuous data in the model. Among the RUV extensions, t-distribution was the most associated with deviations, mainly underestimation. That can be easily tracked down to the use of LAPLACE method commonly known for minimization-related problems, for instance, SE(&#x003a9;<sub><italic>NLME</italic>, <italic>&#x003c5;</italic></sub>) of AUC50 in Asenapine model was 1.66&#x02009;&#x000d7;&#x02009;10<sup>&#x02212;4</sup> which is too close to 0, and an unreasonable estimate for uncertainty, given that the estimate of &#x003a9;<sub><italic>NLME</italic>, <italic>&#x003c5;</italic></sub> of AUC50 is 2.9. This problem of unreasonable estimates in SE(&#x003a9;<sub><italic>NLME</italic></sub>) explain all the extreme deviations seen in Fig. <xref rid="Fig4" ref-type="fig">4</xref>. One of these is PAN0 parameter in asenapine model which &#x003a9;<sub><italic>NLME</italic>, <italic>dTBS</italic></sub> estimate was 168, but its SE(&#x003a9;<sub><italic>NLME</italic>, <italic>dTBS</italic></sub>) was 4.15&#x02009;&#x000d7;&#x02009;10<sup>4</sup>. With these deviations being justified, it is safe to claim that linearization itself or its predictive performance of SE(&#x003a9;<sub><italic>NLME</italic></sub>) showed no built-in drawbacks. The same issues go for RSE(&#x003a9;<sub><italic>NLME</italic></sub>) as not respecting the nature of the data, t-distribution extension, and the unrealistic estimates of &#x003a9;<sub><italic>NLME</italic></sub> and their uncertainties propagated to most of the outliers in Fig. <xref rid="Fig5" ref-type="fig">5</xref>.</p><p id="Par24">In conclusion, we investigated the possible merits of linearization if used to evaluate RUV models for continuous data. Linearization accurately identified the nature of RUV extension if needed and predicted the improvement of fit on its inclusion similar to residual modeling. In addition, linearization can predict the impact of including such RUV extension on the variability assigned to model parameters and their uncertainties, allowing its utilization for variability attribution with automated model building procedures.</p></sec><sec sec-type="supplementary-material"><title>Electronic Supplementary Material</title><sec id="Sec8"><p>
<supplementary-material content-type="local-data" id="MOESM1"><media xlink:href="12248_2019_310_MOESM1_ESM.pdf"><label>ESM 1</label><caption><p>(PDF 157&#x000a0;kb)</p></caption></media></supplementary-material>
</p></sec></sec></body><back><fn-group><fn><p><bold>Publisher&#x02019;s Note</bold></p><p>Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p></fn></fn-group><ack><p>MMA Ibrahim acknowledges the Egyptian Ministry of Higher Education for financial support.</p></ack><notes><title>Compliance with Ethical Standards</title><notes notes-type="COI-statement"><title>Conflict of Interest/Disclosure</title><p id="Par25">There is no involvement, financial or otherwise, that might potentially bias this work.</p></notes></notes><ref-list id="Bib1"><title>References</title><ref id="CR1"><label>1.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gobburu</surname><given-names>JV</given-names></name></person-group><article-title>Pharmacometrics 2020</article-title><source>J Clin Pharmacol</source><year>2010</year><volume>50</volume><fpage>151S</fpage><lpage>157S</lpage><pub-id pub-id-type="doi">10.1177/0091270010376977</pub-id><pub-id pub-id-type="pmid">20881229</pub-id></element-citation></ref><ref id="CR2"><label>2.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Khandelwal</surname><given-names>A</given-names></name><name><surname>Harling</surname><given-names>K</given-names></name><name><surname>Jonsson</surname><given-names>EN</given-names></name><name><surname>Hooker</surname><given-names>AC</given-names></name><name><surname>Karlsson</surname><given-names>MO</given-names></name></person-group><article-title>A fast method for testing covariates in population PK/PD models</article-title><source>AAPS J</source><year>2011</year><volume>13</volume><fpage>464</fpage><lpage>472</lpage><pub-id pub-id-type="doi">10.1208/s12248-011-9289-2</pub-id><pub-id pub-id-type="pmid">21725709</pub-id></element-citation></ref><ref id="CR3"><label>3.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Svensson</surname><given-names>EM</given-names></name><name><surname>Karlsson</surname><given-names>MO</given-names></name></person-group><article-title>Use of a linearization approximation facilitating stochastic model building</article-title><source>J Pharmacokinet Pharmacodyn</source><year>2014</year><volume>41</volume><issue>2</issue><fpage>153</fpage><lpage>158</lpage><pub-id pub-id-type="doi">10.1007/s10928-014-9353-5</pub-id><pub-id pub-id-type="pmid">24623084</pub-id></element-citation></ref><ref id="CR4"><label>4.</label><mixed-citation publication-type="other">Yngman G, Nordgren R, Freiberga S, Karlsson MO. Linearization of full random effects modeling (FREM) for time-efficient automatic covariate assessment. 2018; PAGE 27 Abstr 8750.</mixed-citation></ref><ref id="CR5"><label>5.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ibrahim</surname><given-names>MMA</given-names></name><name><surname>Nordgren</surname><given-names>R</given-names></name><name><surname>Kjellsson</surname><given-names>MC</given-names></name><name><surname>Karlsson</surname><given-names>MO</given-names></name></person-group><article-title>Model-based residual post-processing for residual model identification</article-title><source>AAPS J</source><year>2018</year><volume>20</volume><issue>5</issue><fpage>81</fpage><pub-id pub-id-type="doi">10.1208/s12248-018-0240-7</pub-id><pub-id pub-id-type="pmid">29968184</pub-id></element-citation></ref><ref id="CR6"><label>6.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chi</surname><given-names>EM</given-names></name><name><surname>Reinsel</surname><given-names>GC</given-names></name></person-group><article-title>Models for longitudinal data with random effects and AR(1) errors</article-title><source>J Am Stat Assoc</source><year>1989</year><volume>84</volume><fpage>452</fpage><lpage>459</lpage><pub-id pub-id-type="doi">10.1080/01621459.1989.10478790</pub-id></element-citation></ref><ref id="CR7"><label>7.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Karlsson</surname><given-names>MO</given-names></name><name><surname>Beal</surname><given-names>SL</given-names></name><name><surname>Sheiner</surname><given-names>LB</given-names></name></person-group><article-title>Three new residual error models for population PK/PD analyses</article-title><source>J Pharmacokinet Biopharm</source><year>1995</year><volume>23</volume><issue>6</issue><fpage>651</fpage><lpage>672</lpage><pub-id pub-id-type="doi">10.1007/BF02353466</pub-id><pub-id pub-id-type="pmid">8733951</pub-id></element-citation></ref><ref id="CR8"><label>8.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dosne</surname><given-names>A</given-names></name><name><surname>Bergstrand</surname><given-names>M</given-names></name><name><surname>Karlsson</surname><given-names>MO</given-names></name></person-group><article-title>A strategy for residual error modeling incorporating scedasticity of variance and distribution shape</article-title><source>J Pharmacokinet Pharmacodyn</source><year>2015</year><volume>43</volume><issue>2</issue><fpage>137</fpage><lpage>151</lpage><pub-id pub-id-type="doi">10.1007/s10928-015-9460-y</pub-id><pub-id pub-id-type="pmid">26679003</pub-id></element-citation></ref><ref id="CR9"><label>9.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Box</surname><given-names>GEP</given-names></name><name><surname>Cox</surname><given-names>DR</given-names></name></person-group><article-title>An analysis of transformations</article-title><source>J R Stat Soc B is journal of the Royal Statistical Society, Series B</source><year>1964</year><volume>26</volume><issue>2</issue><fpage>211</fpage><lpage>252</lpage></element-citation></ref><ref id="CR10"><label>10.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Karlsson</surname><given-names>MO</given-names></name><name><surname>Jonsson</surname><given-names>EN</given-names></name><name><surname>Wiltse</surname><given-names>CG</given-names></name><name><surname>Wade</surname><given-names>JR</given-names></name></person-group><article-title>Assumption testing in population pharmacokinetic models: illustrated with an analysis of moxonidine data from congestive heart failure patients</article-title><source>J Pharmacokinet Biopharm</source><year>1998</year><volume>26</volume><issue>2</issue><fpage>207</fpage><lpage>246</lpage><pub-id pub-id-type="doi">10.1023/A:1020561807903</pub-id><pub-id pub-id-type="pmid">9795882</pub-id></element-citation></ref><ref id="CR11"><label>11.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Friberg</surname><given-names>L</given-names></name><name><surname>Greef</surname><given-names>RD</given-names></name><name><surname>Kerbusch</surname><given-names>T</given-names></name><name><surname>Karlsson</surname><given-names>MO</given-names></name></person-group><article-title>Modeling and simulation of the time course of asenapine exposure response and dropout patterns in acute schizophrenia</article-title><source>Clin Pharmacol Ther</source><year>2009</year><volume>86</volume><issue>1</issue><fpage>84</fpage><lpage>91</lpage><pub-id pub-id-type="doi">10.1038/clpt.2009.44</pub-id><pub-id pub-id-type="pmid">19387434</pub-id></element-citation></ref><ref id="CR12"><label>12.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zingmark</surname><given-names>P</given-names></name><name><surname>Ekblom</surname><given-names>M</given-names></name><name><surname>Odergren</surname><given-names>T</given-names></name><name><surname>Ashwood</surname><given-names>T</given-names></name><name><surname>Lyden</surname><given-names>P</given-names></name><name><surname>Karlsson</surname><given-names>MO</given-names></name><name><surname>Jonsson</surname><given-names>EN</given-names></name></person-group><article-title>Population pharmacokinetics of clomethiazole and its effect on the natural course of sedation in acute stroke patients</article-title><source>Br J Clin Pharmacol</source><year>2003</year><volume>56</volume><issue>2</issue><fpage>173</fpage><lpage>183</lpage><pub-id pub-id-type="doi">10.1046/j.0306-5251.2003.01850.x</pub-id><pub-id pub-id-type="pmid">12895190</pub-id></element-citation></ref><ref id="CR13"><label>13.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bogason</surname><given-names>A</given-names></name><name><surname>Quartino</surname><given-names>AL</given-names></name><name><surname>Lafolie</surname><given-names>P</given-names></name><name><surname>Masquelier</surname><given-names>M</given-names></name><name><surname>Karlsson</surname><given-names>MO</given-names></name><name><surname>Paul</surname><given-names>C</given-names></name><name><surname>Vitols</surname><given-names>S</given-names></name></person-group><article-title>Inverse relationship between leukaemic cell burden and plasma concentrations of daunorubicin in patients with acute myeloid leukaemia</article-title><source>Br J Clin Pharmacol</source><year>2011</year><volume>71</volume><issue>4</issue><fpage>514</fpage><lpage>521</lpage><pub-id pub-id-type="doi">10.1111/j.1365-2125.2010.03894.x</pub-id><pub-id pub-id-type="pmid">21204910</pub-id></element-citation></ref><ref id="CR14"><label>14.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hornestam</surname><given-names>B</given-names></name><name><surname>Jerling</surname><given-names>M</given-names></name><name><surname>Karlsson</surname><given-names>MO</given-names></name><name><surname>Held</surname><given-names>P</given-names></name></person-group><article-title>Intravenously administered digoxin in patients with acute atrial fibrillation: a population pharmacokinetic/pharmacodynamic analysis based on the Digitalis in Acute Atrial Fibrillation trial</article-title><source>Eur J Clin Pharmacol</source><year>2003</year><volume>58</volume><issue>11</issue><fpage>747</fpage><lpage>755</lpage><pub-id pub-id-type="doi">10.1007/s00228-002-0553-3</pub-id><pub-id pub-id-type="pmid">12634981</pub-id></element-citation></ref><ref id="CR15"><label>15.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jonsson</surname><given-names>S</given-names></name><name><surname>Cheng</surname><given-names>Y</given-names></name><name><surname>Edenius</surname><given-names>C</given-names></name><name><surname>Lees</surname><given-names>KR</given-names></name><name><surname>Odergren</surname><given-names>T</given-names></name><name><surname>Karlsson</surname><given-names>MO</given-names></name></person-group><article-title>Population pharmacokinetic modeling and estimation of dosing strategy for NXY-059, a nitrone being developed for stroke</article-title><source>Clin Pharmacokinet</source><year>2005</year><volume>44</volume><issue>8</issue><fpage>863</fpage><lpage>878</lpage><pub-id pub-id-type="doi">10.2165/00003088-200544080-00007</pub-id><pub-id pub-id-type="pmid">16029070</pub-id></element-citation></ref><ref id="CR16"><label>16.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jonsson</surname><given-names>S</given-names></name><name><surname>Davidse</surname><given-names>A</given-names></name><name><surname>Wilkins</surname><given-names>J</given-names></name><name><surname>Walt</surname><given-names>JV</given-names></name><name><surname>Simonsson</surname><given-names>US</given-names></name><name><surname>Karlsson</surname><given-names>MO</given-names></name><name><surname>Mcilleron</surname><given-names>H</given-names></name></person-group><article-title>Population pharmacokinetics of ethambutol in South African tuberculosis patients</article-title><source>Antimicrob Agents Chemother</source><year>2011</year><volume>55</volume><issue>9</issue><fpage>4230</fpage><lpage>4237</lpage><pub-id pub-id-type="doi">10.1128/AAC.00274-11</pub-id><pub-id pub-id-type="pmid">21690284</pub-id></element-citation></ref><ref id="CR17"><label>17.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Silber</surname><given-names>HE</given-names></name><name><surname>Jauslin</surname><given-names>PM</given-names></name><name><surname>Frey</surname><given-names>N</given-names></name><name><surname>Gieschke</surname><given-names>R</given-names></name><name><surname>Simonsson</surname><given-names>US</given-names></name><name><surname>Karlsson</surname><given-names>MO</given-names></name></person-group><article-title>An integrated model for glucose and insulin regulation in healthy volunteers and type 2 diabetic patients following intravenous glucose provocations</article-title><source>J Clin Pharmacol</source><year>2007</year><volume>47</volume><issue>9</issue><fpage>1159</fpage><lpage>1171</lpage><pub-id pub-id-type="doi">10.1177/0091270007304457</pub-id><pub-id pub-id-type="pmid">17766701</pub-id></element-citation></ref><ref id="CR18"><label>18.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dorlo</surname><given-names>T. P. C.</given-names></name><name><surname>van Thiel</surname><given-names>P. P. A. M.</given-names></name><name><surname>Huitema</surname><given-names>A. D. R.</given-names></name><name><surname>Keizer</surname><given-names>R. J.</given-names></name><name><surname>de Vries</surname><given-names>H. J. C.</given-names></name><name><surname>Beijnen</surname><given-names>J. H.</given-names></name><name><surname>de Vries</surname><given-names>P. J.</given-names></name></person-group><article-title>Pharmacokinetics of Miltefosine in Old World Cutaneous Leishmaniasis Patients</article-title><source>Antimicrobial Agents and Chemotherapy</source><year>2008</year><volume>52</volume><issue>8</issue><fpage>2855</fpage><lpage>2860</lpage><pub-id pub-id-type="doi">10.1128/AAC.00014-08</pub-id><pub-id pub-id-type="pmid">18519729</pub-id></element-citation></ref><ref id="CR19"><label>19.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Friberg</surname><given-names>LE</given-names></name><name><surname>Henningsson</surname><given-names>A</given-names></name><name><surname>Maas</surname><given-names>H</given-names></name><name><surname>Nguyen</surname><given-names>L</given-names></name><name><surname>Karlsson</surname><given-names>MO</given-names></name></person-group><article-title>Model of chemotherapy-induced myelosuppression with parameter consistency across drugs</article-title><source>J Clin Oncol</source><year>2002</year><volume>20</volume><issue>24</issue><fpage>4713</fpage><lpage>4721</lpage><pub-id pub-id-type="doi">10.1200/JCO.2002.02.140</pub-id><pub-id pub-id-type="pmid">12488418</pub-id></element-citation></ref><ref id="CR20"><label>20.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wahlby</surname><given-names>U</given-names></name><name><surname>Thomson</surname><given-names>AH</given-names></name><name><surname>Milligan</surname><given-names>PA</given-names></name><name><surname>Karlsson</surname><given-names>MO</given-names></name></person-group><article-title>Models for time-varying covariates in population pharmacokinetic-pharmacodynamic analysis</article-title><source>Br J Clin Pharmacol</source><year>2004</year><volume>58</volume><issue>4</issue><fpage>367</fpage><lpage>377</lpage><pub-id pub-id-type="doi">10.1111/j.1365-2125.2004.02170.x</pub-id><pub-id pub-id-type="pmid">15373929</pub-id></element-citation></ref><ref id="CR21"><label>21.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Karlsson</surname><given-names>MO</given-names></name><name><surname>Wade</surname><given-names>JR</given-names></name><name><surname>Loumaye</surname><given-names>E</given-names></name><name><surname>Munafo</surname><given-names>A</given-names></name></person-group><article-title>The population pharmacokinetics of recombinant- and urinary-human follicle stimulating hormone in women</article-title><source>Br J Clin Pharmacol</source><year>2002</year><volume>45</volume><issue>1</issue><fpage>13</fpage><lpage>20</lpage><pub-id pub-id-type="doi">10.1046/j.1365-2125.1998.00644.x</pub-id></element-citation></ref><ref id="CR22"><label>22.</label><mixed-citation publication-type="other">Beal S, Sheiner LB, Boeckmann A, Bauer RJ, NONMEM user&#x02019;s guides. <italic>Icon Development Solutions</italic>, Ellicott City, MD, USA, 1989-2009; 2009.</mixed-citation></ref><ref id="CR23"><label>23.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lindbom</surname><given-names>L</given-names></name><name><surname>Pihlgren</surname><given-names>P</given-names></name><name><surname>Jonsson</surname><given-names>EN</given-names></name></person-group><article-title>PsN-toolkit&#x02014;a collection of computer intensive statistical methods for non-linear mixed effect modeling using NONMEM</article-title><source>Comput Methods Prog Biomed</source><year>2005</year><volume>79</volume><issue>3</issue><fpage>241</fpage><lpage>257</lpage><pub-id pub-id-type="doi">10.1016/j.cmpb.2005.04.005</pub-id></element-citation></ref><ref id="CR24"><label>24.</label><mixed-citation publication-type="other">Team RC. R: a language and environment for statistical computing. Vienna, Austria: 2014. Available from: <ext-link ext-link-type="uri" xlink:href="http://www.r-project.org">http://www.R-project.org</ext-link>.</mixed-citation></ref></ref-list></back></article>