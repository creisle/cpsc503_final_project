
Abstract

We investigated the possible advantages of using linearization to evaluate models of residual unexplained variability (RUV) for automated model building in a similar fashion to the recently developed method “residual modeling.” Residual modeling, although fast and easy to automate, cannot identify the impact of implementing the needed RUV model on the imprecision of the rest of model parameters. We used six RUV models to be tested with 12 real data examples. Each example was first linearized; then, we assessed the agreement in improvement of fit between the base model and its extended models for linearization and conventional analysis, in comparison to residual modeling performance. Afterward, we compared the estimates of parameters’ variabilities and their uncertainties obtained by linearization to conventional analysis. Linearization accurately identified and quantified the nature and magnitude of RUV model misspecification similar to residual modeling. In addition, linearization identified the direction of change and quantified the magnitude of this change in variability parameters and their uncertainties. This method is implemented in the software package PsN for automated model building/evaluation with continuous data.

Electronic supplementary material

The online version of this article (10.1208/s12248-019-0310-5) contains supplementary material, which is available to authorized users.



INTRODUCTION

Nonlinear mixed effect (NLME) modeling, commonly known as the population approach, is increasingly used to describe longitudinal data from preclinical/clinical experiments, either to improve the efficiency of the drug development process and subsequent dosing, or increase the understanding of the studied underlying pathophysiological system. In contrast to naive pooling approach, which ignores individual differences, and two-stage approach, which does not distinguish between subject and observation variability, NLME models allow pooling of sparse data from different subjects while simultaneously quantifying multiple levels of variability, thanks to its mixed effects nature. In mixed-effects analysis, population parameters are included in a model as fixed effects, and the variability within this population as random effects. Random effects can incorporate variability on both the subject and observation levels, as inter-individual variability (IIV), between occasion variability, between study variability, and residual unexplained variability (RUV). This ability to identify different sources of variability is particularly critical to many clinical applications, e.g., therapeutic drug monitoring.

For highly nonlinear models, extending the structural base model to include covariates or test different models for random effects can be tedious and interrupted by numerical difficulties. These problems increase exponentially with increasing the complexity of the structure, covariate, and variability models. To overcome such computational and time-intensive burden, linear approximation of first-order conditional estimation (FOCE) method was proposed and applied as a diagnostic tool for testing covariates and random effects. When successfully implemented, linearization substantially reduced runtimes compared to standard NLME models as the fixed effects are not estimated in the linearized models, but fixed to their estimates from the fit of the NLME model. Linearized models were shown to result in similar objective function values (OFVs) to the NLME models, and accurately identify significant covariate relations and stochastic components similar to conventional analysis. Hence, linearization output models in a standardized coding format, linearization was also recommended for automated model building by coupling to other covariate modeling algorithms as stepwise covariate method (SCM) or full random effects covariate modeling (FREM). However, linearized models still need to be estimated given the original observations similar to NLME models, so it might be sensitive to local minima or other estimation-related issues, especially in presence of interactions between empirical Bayes estimates and RUV models. Major deviations between the OFV of the linearized structure base model and its corresponding NLME model should be interpreted as a failure of implementation of linearization and must be solved prior to further investigations using the linearized model. It has not been shown previously that random effects estimated in linearized models or their uncertainties’ have similar values if estimated in the corresponding NLME models, which if true, will support the role of linearization in automated model building to predict changes in random variability assigned to model parameters upon the inclusion of a potential covariate or adoption of a new RUV model.

Meanwhile, a new method “residual modeling” was proposed as a fast and robust diagnostic tool for assessing RUV models for NLME analysis with continuous outcomes. Residual modeling treats the outputted residuals from a NLME model execution as a dependent variable to model its distribution’s mean and variance by a linear base model, then this base model is extended to assess different RUV extensions. The improvement in the fit between the residuals base model and its extended versions can accurately identify the nature and magnitude of potential RUV model improvements/misspecifications, and hence, residual modeling has been already implemented for automated model building. Residual modeling uses a built-in library of six RUV extensions to model the variance of the residuals’ distribution from a NLME model execution. The built-in library includes autoregressive (AR1), dynamic transform both sides (dTBS), residuals’ IIV, power, t-distribution, and time-varying RUV models (6–10). The investigated residuals were conditional weighted residuals (CWRES), conditional weighted residuals with interaction (CWRESI), individual weighted residuals (IWRES), and normalized prediction distribution errors (NPDE); CWRES outperformed the rest, as CWRES modeling correctly identified the type of the needed RUV model and accurately predicted both the estimates of parameters governing this RUV model and the magnitude of improvement of fit after implementing such RUV model. Residual modeling does not suffer from local minima problems or estimation related issues, as it is using residuals data, not the original observations. This is an advantage for its purpose in fast and robust selection of the best RUV model, but then by definition, it cannot predict the impact of implementing a new RUV model on random variability assigned to the rest of model parameters or their uncertainties.

Here, we investigated if linearization can predict variability attribution for automated model building on the inclusion of a new RUV extension. We used the same six RUV models from our previous work for residual modeling. First, we compared the performance of linearization to residual modeling in selecting the best RUV extension; then, we compared random effects’ estimates and uncertainties on linearized models with the different RUV extensions to their corresponding NLME models.


